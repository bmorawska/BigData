{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Zadanie 2 Przetwarzanie i Analiza Dużych zbiorów danych\n",
    "Barbara Morawska 234096\n",
    "Andrzej Sasinowski 234118\n",
    "Marcin Markiewicz 234090"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def prepare_data():\n",
    "    return  sc.textFile(\"FileStore/shared_uploads/234090@edu.p.lodz.pl/4.txt\") \\\n",
    "           .map(lambda line:line.split(\"\\t\")) \\\n",
    "           .map(lambda line: (int(line[0]), list(map(lambda x: int(x), line[1].split(',')))))\n",
    "def get_pairs(line):\n",
    "    user = line[0]\n",
    "    friends = line[1]\n",
    "    friends_pairs = []\n",
    "    for friend in friends:\n",
    "        friends_pairs.append(((user, friend),0)) # direct friendships\n",
    "    for friend1 in friends:\n",
    "       for friend2 in friends:\n",
    "           if(friend1 != '' and friend2 != ''):  \n",
    "                if friend1 != friend2:\n",
    "                    friends_pairs.append(((friend1, friend2), 1)) #indirect friendships\n",
    "    return friends_pairs\n",
    "def get_recommendation(m): \n",
    "    return [(m[0][0], (m[0][1], m[1])), (m[0][1], (m[0][0], m[1]))]\n",
    "def sort_and_slice_recommendation(recs):\n",
    "    recs.sort(key=lambda x: (-x[1], x[0]))\n",
    "    return list(map(lambda x: x[0], recs))[:10]\n",
    "   \n",
    "def setup():\n",
    "    data = prepare_data()\n",
    "    pairs = data.flatMap(get_pairs)\n",
    "    pairs.cache()\n",
    "    recommendations =  pairs.groupByKey() \\\n",
    "                              .filter(lambda x: 0 not in x[1]) \\\n",
    "                              .map(lambda x: (x[0], sum(x[1]))) \\\n",
    "                              .flatMap(get_recommendation) \\\n",
    "                              .groupByKey() \\\n",
    "                              .map(lambda m: (m[0], sort_and_slice_recommendation(list(m[1]))))\\\n",
    "                              .sortByKey() \n",
    "                             \n",
    "    output = recommendations.collect()\n",
    "    output = ''.join(str(list(map(lambda m: (str(m[0])+'\\t'+str(m[1])+'\\n'),output))))\n",
    "    dbutils.fs.put(\"/FileStore/Shared/output1.txt\", output)\n",
    "setup()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Do Stworzenia naszego algorytmu wykorzystaliśmy Apache Spark wraz z językiem Python, do testów wykorzystaliśmy databricks. Posłużyliśmy się starszym API Sparka RDD. Apache Spark rozszerza bibliotekę narzędzi pythona o wiele przydatnych funkcji jak np flatMap czy groupByKey."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Rezultaty dla zmiennych określonych w zadaniu\n",
    "924 [439, 2409, 6995, 11860, 15416, 43748, 45881]\n",
    "8941 [8943, 8944, 8940]\n",
    "8942 [8939, 8940, 8943, 8944]\n",
    "9019 [9022, 317, 9023]\n",
    "9020 [9021, 9016, 9017, 9022, 317, 9023]\n",
    "9021 [9020, 9016, 9017, 9022, 317, 9023]\n",
    "9022 [9019, 9020, 9021, 317, 9016, 9017, 9023]\n",
    "9990 [13134, 13478, 13877, 34299, 34485, 34642, 37941]\n",
    "9992 [9987, 9989, 35667, 9991]\n",
    "9993 [9991, 13134, 13478, 13877, 34299, 34485, 34642, 37941]"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}