{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zadanie 4 - Przetwarzanie i analiza dużych zbiorów danych"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Barbara Morawska     234096\n",
    "    Andrzej Sasinowski   234118\n",
    "    Marcin Markiewicz    234090"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Program został wykonany w języku Python przy użyciu Apache Spark. Program na podstawie danych wczytanych z pliku 4.txt wyznacza przy pomocy zaimplementowanego algorytmu A-priori reguły asocjacyjne dla dwójek oraz trójek produktów, a następnie wypisuje po 5 reguł z dwójek i trójek o najwyższym współczynniku ufności. W przypadku równych współczynników zastosowany jest porządek leksykograficzny według poprzedników."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kod programu:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from operator import add\n",
    "import pyspark\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_elements(elements, threshold_supp):\n",
    "    elements_counted = elements.map(lambda key: (key, 1)).reduceByKey(add)\n",
    "    elements_counted_filtered = elements_counted.filter(lambda element_dict: element_dict[1] >= threshold_supp)\n",
    "    return dict(elements_counted_filtered.collect())\n",
    "\n",
    "\n",
    "def calculate_supp(session_data, elements, cardinality, threshold_supp):\n",
    "    n_element_set = {}\n",
    "    for combination in itertools.combinations(sorted(elements), cardinality):\n",
    "        n_element_set[combination] = 0\n",
    "    \n",
    "    for session in session_data.toLocalIterator():\n",
    "        session_filtered = sorted([element for element in session if element in elements])\n",
    "        for combination in itertools.combinations(session_filtered, cardinality):\n",
    "            if combination in n_element_set:\n",
    "                n_element_set[combination] += 1\n",
    "    \n",
    "    n_element_set_filtered = filter(lambda element_dict: element_dict[1] >= threshold_supp, n_element_set.items())\n",
    "    return dict(n_element_set_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def two_elements_case(element_set, element_subset):\n",
    "    rules = []\n",
    "    for key, value in element_set.items():\n",
    "        ## X --> Y, Y --> X\n",
    "        rules.append((list([key[0], key[1]]), value / element_subset[key[0]]))\n",
    "        rules.append((list([key[1], key[0]]), value / element_subset[key[1]]))\n",
    "    return rules\n",
    "    \n",
    "    \n",
    "def three_elements_case(element_set, element_subset):\n",
    "    rules = []\n",
    "    for key, value in element_set.items():\n",
    "        ## X,Y --> Z, X,Z --> Y, Y,Z --> Z\n",
    "        for combination in itertools.combinations(key, 2):\n",
    "            if combination in element_subset:\n",
    "                p = list(combination)\n",
    "                q = list(set(key) - set(combination))\n",
    "                rules.append((p, q, value / element_subset[combination]))\n",
    "    return rules\n",
    "    \n",
    "\n",
    "def assembly_rules(element_set, element_subset, set_cardinality):\n",
    "    get_function = {2: two_elements_case, 3: three_elements_case}\n",
    "    which_case = get_function.get(set_cardinality)\n",
    "    rules = which_case(element_set, element_subset)\n",
    "    rules.sort(reverse=True, key=lambda x: x[set_cardinality-1])\n",
    "    return rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_THRESHOLD_SUPP = 100\n",
    "\n",
    "## Prepare data\n",
    "sc = pyspark.SparkContext.getOrCreate()\n",
    "session_data = sc.textFile('4.txt').map(lambda line: line[:-1].split(' '))\n",
    "all_elements = session_data.flatMap(lambda element: element)\n",
    "\n",
    "## 1-element supp\n",
    "elements_single = count_elements(all_elements, DEFAULT_THRESHOLD_SUPP)\n",
    "\n",
    "## 2-elements supp\n",
    "elements_double = calculate_supp(session_data, elements_single, 2, DEFAULT_THRESHOLD_SUPP)\n",
    "elements_double_unique = set(itertools.chain.from_iterable(elements_double)) \n",
    "\n",
    "## 3-elements supp\n",
    "elements_triple = calculate_supp(session_data, elements_double_unique, 3, DEFAULT_THRESHOLD_SUPP)\n",
    "\n",
    "## Assembly rules and calculate confidence\n",
    "rules_double = assembly_rules(elements_double, elements_single, 2)\n",
    "rules_triple = assembly_rules(elements_triple, elements_double, 3)\n",
    "\n",
    "# Print number of of 1-element sets\n",
    "print(\"Liczba zbiorów jednoelementowych: {}\".format(len(elements_single)))\n",
    "\n",
    "# Get five best association rules for both sets\n",
    "\n",
    "print(\"\\n5 reguł asocjacyjnych dla dwójek o najwyższym współczynniku ufności: \")\n",
    "for rule in rules_double[:5]:\n",
    "    print(rule)\n",
    "    \n",
    "print(\"\\n5 reguł asocjacyjnych dla trójek o najwyższym współczynniku ufności: \")\n",
    "for rule in rules_triple[:5]:\n",
    "    print(rule)\n",
    "\n",
    "sc.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wyniki:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Liczba zbiorów jednoelementowych: 647\n",
    "    \n",
    "    5 reguł asocjacyjnych dla dwójek o najwyższym współczynniku ufności: \n",
    "    (['DAI93865', 'FRO40251'], 1.0)\n",
    "    (['GRO85051', 'FRO40251'], 0.999176276771005)\n",
    "    (['GRO38636', 'FRO40251'], 0.9906542056074766)\n",
    "    (['ELE12951', 'FRO40251'], 0.9905660377358491)\n",
    "    (['DAI88079', 'FRO40251'], 0.9867256637168141)\n",
    "    \n",
    "    5 reguł asocjacyjnych dla trójek o najwyższym współczynniku ufności: \n",
    "    (['DAI23334', 'ELE92920'], ['DAI62779'], 1.0)\n",
    "    (['DAI31081', 'GRO85051'], ['FRO40251'], 1.0)\n",
    "    (['DAI55911', 'GRO85051'], ['FRO40251'], 1.0)\n",
    "    (['DAI62779', 'DAI88079'], ['FRO40251'], 1.0)\n",
    "    (['DAI75645', 'GRO85051'], ['FRO40251'], 1.0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
